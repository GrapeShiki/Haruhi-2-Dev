{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOH5KcIjIuvT50Rs4Zg7Qkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Haruhi-2-Dev/blob/main/notebook/%E9%A2%9D%E5%A4%96%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] RoleLLM的数据\n",
        "- [ ] 其他中文的hf的一些数据\n",
        "- [ ] ChatHaruhi54K本身的数据"
      ],
      "metadata": {
        "id": "GglE46SYH83z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里我们假设输入数据已经组织成了hf格式\n",
        "\n",
        "可以有效载入到chatbot中"
      ],
      "metadata": {
        "id": "vPt6Zysa5H78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai tiktoken langchain chromadb datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6VrCMIb5T_j",
        "outputId": "36bbe0cf-628f-445b-db2a-41102d207c61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.4/502.4 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.4/699.4 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练的参数设定"
      ],
      "metadata": {
        "id": "tl7H3ltbFaEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K_SEARCH = 5\n",
        "MAX_LEN_STORY = 1000 #这个是按照token算的\n",
        "MAX_LEN_HISTORY = 1200 # count with token"
      ],
      "metadata": {
        "id": "NFrw2aW_Fbsh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "key = \"key is not necessary here\"\n",
        "key_bytes = key.encode()\n",
        "os.environ[\"OPENAI_API_KEY\"] = key_bytes.decode('utf-8')"
      ],
      "metadata": {
        "id": "_fuSHAHU8-Kc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_datas = []\n",
        "\n",
        "role_names = ['令狐冲', '岳不群', '鸠摩智', '萧峰', '丁春秋', '虚竹', '谢逊', '张无忌', '赵敏', '周芷若', '黄药师', '欧阳锋', '黄蓉', '郭靖', '孙悟空']\n",
        "\n",
        "hf_roles = [\n",
        "    \"chengli-thu/linghuchong\",\n",
        "    \"chengli-thu/yuebuqun\",\n",
        "    \"hhhwmws/jiumozhi\",\n",
        "    \"hhhwmws/xiaofeng\",\n",
        "    \"hhhwmws/dingchunqiu\",\n",
        "    \"hhhwmws/xuzhu\",\n",
        "    \"hhhwmws/xiexun\",\n",
        "    \"hhhwmws/zhangwuji\",\n",
        "    \"hhhwmws/zhaomin\",\n",
        "    \"hhhwmws/zhouzhiruo\",\n",
        "    \"hhhwmws/huangyaoshi\",\n",
        "    \"hhhwmws/ouyangfeng\",\n",
        "    \"hhhwmws/huangrong\",\n",
        "    \"hhhwmws/guojing\",\n",
        "    \"sibozhu/wukong\"\n",
        "]\n",
        "\n",
        "for role, hf_add in zip(role_names, hf_roles):\n",
        "    agent_data = {\n",
        "        \"hf_str\":hf_add,\n",
        "        \"role\":role,\n",
        "        \"embedding\":\"luotuo_openai\"\n",
        "    }\n",
        "    agent_datas.append(agent_data)\n"
      ],
      "metadata": {
        "id": "9tTG55MfI43z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "role_from_roleLLM = ['Caesar', 'Sonny', 'Angel', 'Jigsaw', 'John Doe', 'Freddy Krueger', 'Colonel Hans Landa', 'Gregory House', 'Gaston', 'HAL 9000', 'Mark Renton', 'Coriolanus', 'Oliver Queen', 'Bruno Antony', 'D_Artagnan', 'Dr. Frank-N-Furter', 'Tugg Speedman', 'Stifler', 'Jeff Spicoli', 'Rorschach', 'Paul Vitti', 'Logan', 'Judge Dredd', 'Karl Childers', 'Rachel Lang', 'Queen Elizabeth I', 'Tyrion Lannister', 'John Keating', 'Wade Wilson', 'Lyn Cassady', 'Dr. Hannibal Lecter', 'Violet Weston', 'Po', 'Malcolm X', 'Willie Soke', 'Jack Torrance', 'Alvy Singer', 'Colonel Nathan R. Jessep', 'Andrew Detmer', 'Fred Flintstone', 'Frank T.J. Mackey', 'Stephen Hawking', 'Lestat de Lioncourt', 'Jack Sparrow', 'John Coffey', 'Murphy MacManus', 'John Dillinger', 'Jackie Moon', 'Peter Parker', 'Abraham Lincoln', 'James Carter', 'Tyler Hawkins', 'Stanley Ipkiss', 'Mater', 'Professor G.H. Dorr', 'Juno MacGuff', 'Seth', 'Sherlock Holmes', 'Truman Capote', 'Shrek', 'Travis Bickle', 'Jack', 'Tom Ripley', 'The Dude', 'David Aames', 'Twilight Sparkle', 'Antonio Salieri', 'Judy Hoops', 'Randle McMurphy', 'Thor', 'Walt Kowalski', 'Fletcher Reede', 'Theodore Twombly', 'James Brown', 'Paul Conroy', 'James Bond', 'Queen Catherine', 'Harvey Milk', 'Caden Cotard', 'Leonard Shelby', 'Jim Morrison', 'Pat Solitano', 'Benjamin Button', 'Robert Angier', 'Lucifer Morningstar', 'Jordan Belfort', 'Coach Eric Taylor', 'Mary Sibley', 'Klaus Mikaelson', 'Raylan Givens', 'Sheldon Cooper', 'Michael Scott', 'Leroy Jethro Gibbs', 'Doctor Who', 'Blair Waldorf']\n",
        "print(len(role_from_roleLLM))\n",
        "\n",
        "# # for debug\n",
        "# role_from_roleLLM = role_from_roleLLM[:5]\n",
        "# print(len(role_from_roleLLM))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ICPcams6gef",
        "outputId": "4ab44005-3eb9-4034-f1d8-fc68ae338f65"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for role in role_from_roleLLM:\n",
        "    agent_data = {\n",
        "        \"hf_str\":'silk-road/ChatHaruhi-from-RoleLLM/' + role,\n",
        "        \"role\":role,\n",
        "        \"embedding\":\"bge_en\"\n",
        "    }\n",
        "    agent_datas.append(agent_data)"
      ],
      "metadata": {
        "id": "mJHYw8kVIlGk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(agent_datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqd9uU_RMqtN",
        "outputId": "8ac31409-e6cd-4d32-d3dd-a3d8133c19c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content\n",
        "!rm -rf /content/Haruhi-2-Dev\n",
        "!git clone https://github.com/LC1332/Haruhi-2-Dev\n",
        "%cd /content/Haruhi-2-Dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udVfoKmi9Tme",
        "outputId": "99a2b364-3b95-4def-d452-2e2afcca0a13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Haruhi-2-Dev'...\n",
            "remote: Enumerating objects: 898, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 898 (delta 138), reused 152 (delta 105), pack-reused 693\u001b[K\n",
            "Receiving objects: 100% (898/898), 105.85 MiB | 16.36 MiB/s, done.\n",
            "Resolving deltas: 100% (468/468), done.\n",
            "/content/Haruhi-2-Dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6vNMO1f_E55",
        "outputId": "a137b954-1d3a-440f-b803-822042fcb8bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatHaruhi  data  LICENSE  notebook  Readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi import ChatHaruhi\n",
        "\n",
        "from ChatHaruhi.ChromaDB import ChromaDB\n",
        "\n",
        "class ChatHaruhiTrain(ChatHaruhi):\n",
        "\n",
        "    def build_story_db_from_vec( self, texts, vecs ):\n",
        "        self.db = ChromaDB()\n",
        "        self.stories = texts\n",
        "        self.db.init_from_docs( vecs, texts)\n",
        "\n",
        "    def add_story_with_expire(self, query, expire_story):\n",
        "        if self.db is None:\n",
        "            print(\"No vec DB！\")\n",
        "            return\n",
        "\n",
        "        query_vec = self.embedding(query)\n",
        "        stories = self.db.search(query_vec, self.k_search)\n",
        "\n",
        "        story_string = self.story_prefix_prompt + self.dialogue_divide_token\n",
        "\n",
        "        sum_story_token = self.tokenizer(story_string)\n",
        "\n",
        "        for story in stories:\n",
        "            if expire_story.strip() == story.strip():\n",
        "                continue\n",
        "\n",
        "            story_token = self.tokenizer(story.strip()) + self.tokenizer(self.dialogue_divide_token)\n",
        "            if sum_story_token + story_token > self.max_len_story:\n",
        "                break\n",
        "            else:\n",
        "                sum_story_token += story_token\n",
        "                story_string += story.strip() + self.dialogue_divide_token\n",
        "\n",
        "        self.llm.user_message(story_string)\n",
        "\n",
        "    def generate_prompt(self, query, history_str, expire_story ):\n",
        "        # 这里修改下其他超参，不规范删了\n",
        "        # self.k_search = 5\n",
        "        # self.max_len_story = 1500\n",
        "        # self.max_len_history = 1200\n",
        "        self.story_prefix_prompt = \"\\nClassic scenes for the role are as follows:\"\n",
        "\n",
        "        self.llm.initialize_message()\n",
        "\n",
        "        self.llm.system_message(self.system_prompt)\n",
        "\n",
        "        self.add_story_with_expire(query, expire_story)\n",
        "\n",
        "        # self.add_history(history)\n",
        "        history_message = self.dialogue_divide_token + history_str\n",
        "        self.llm.user_message(history)\n",
        "\n",
        "        self.llm.user_message(query)\n",
        "\n",
        "        # self.llm.user_message(target)\n",
        "\n",
        "        return self.llm.messages\n",
        "\n",
        "    def add_history(self, history_list):\n",
        "\n",
        "        if len(history_list) == 0:\n",
        "            return\n",
        "\n",
        "        sum_history_token = 0\n",
        "        flag = 0\n",
        "        for history in history_list:\n",
        "            current_count = 0\n",
        "            if history is not None:\n",
        "                current_count += self.tokenizer(history)\n",
        "\n",
        "            sum_history_token += current_count\n",
        "            if sum_history_token > self.max_len_history:\n",
        "                break\n",
        "            else:\n",
        "                flag += 1\n",
        "\n",
        "        if flag == 0:\n",
        "            print('warning! no history added. the last dialogue is too long.')\n",
        "\n",
        "        # 是否添加历史前缀，\n",
        "        history_message = \"\"\n",
        "        for history in history_list[-flag:]:\n",
        "            history_message += history\n",
        "        self.llm.user_message(history_message)"
      ],
      "metadata": {
        "id": "WcWlOGEv9MGd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tuples_from_story(role_name, story):\n",
        "    story_tuples = []\n",
        "\n",
        "    lines = story.split('\\n')\n",
        "\n",
        "    n = len(lines)\n",
        "\n",
        "    datas = []\n",
        "\n",
        "    for i in range(1, n):\n",
        "        line = lines[i]\n",
        "        if line.startswith(role_name):\n",
        "            query = lines[i-1]\n",
        "            target = line\n",
        "            history_str = \"\"\n",
        "            for j in range(0, i-1):\n",
        "                history_str += lines[j] + \"\\n\"\n",
        "\n",
        "            history_str = history_str.strip()\n",
        "            data = (query, target, history_str, story)\n",
        "            datas.append(data)\n",
        "\n",
        "    return datas"
      ],
      "metadata": {
        "id": "RBDP5YWR_cMe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "对RoleLLM的数据进行组织"
      ],
      "metadata": {
        "id": "KzIajWcI7C-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "abWj2YNQCFFc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_datas[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfGOi-2NKaBT",
        "outputId": "ab7f8a33-455e-48c3-b477-ec917ab234f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hf_str': 'chengli-thu/linghuchong', 'role': '令狐冲', 'embedding': 'luotuo_openai'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lynZ4m35BGy",
        "outputId": "0d447cff-bc77-4352-8957-726eb920e30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 490/2747 [02:43<12:11,  3.09it/s]"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "save_datas = []\n",
        "\n",
        "# for role_name in tqdm(role_from_roleLLM):\n",
        "\n",
        "for agent_data in agent_datas:\n",
        "    role_name = agent_data['role']\n",
        "    hf_address = agent_data['hf_str']\n",
        "    embedding = agent_data['embedding']\n",
        "\n",
        "    chatbot = ChatHaruhiTrain( role_from_hf = hf_address, \\\n",
        "                      llm = 'openai',\n",
        "                      embedding = embedding)\n",
        "    stories = chatbot.stories\n",
        "\n",
        "    chatbot.k_search = K_SEARCH\n",
        "    chatbot.max_len_story = MAX_LEN_STORY\n",
        "    chatbot.max_len_history = MAX_LEN_HISTORY\n",
        "\n",
        "    all_tuples = []\n",
        "\n",
        "    for story in stories:\n",
        "        # print(story)\n",
        "        tuples = extract_tuples_from_story(role_name, story )\n",
        "\n",
        "        all_tuples += tuples\n",
        "\n",
        "    for query, target, history, story in tqdm(all_tuples):\n",
        "        messages = chatbot.generate_prompt(query, history, story)\n",
        "        # print(prompt)\n",
        "\n",
        "        prompt = \"\"\n",
        "\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, HumanMessage):\n",
        "                prompt += msg.content + \"\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += msg.content + \"\\n\"\n",
        "            elif isinstance(msg, SystemMessage):\n",
        "                prompt += msg.content + \"\\n\"\n",
        "\n",
        "        save_data = {\n",
        "            'context': prompt,\n",
        "            'target': target\n",
        "        }\n",
        "\n",
        "        save_datas.append(save_data)\n",
        "\n",
        "        # break\n",
        "\n",
        "    # break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(save_data['context'])\n",
        "\n",
        "print()\n",
        "\n",
        "print(save_data['target'])"
      ],
      "metadata": {
        "id": "nxYt8Of0L5kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwG1ZHv7MZ9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save_datas是一个list of dict\n",
        "save_name = \"/content/ChatHaruhi_rolellm_fusion.jsonl\"\n",
        "\n",
        "帮我用utf-8编码，jsonl格式，保存save_datas中的数据\n",
        "ensure_ascii = False"
      ],
      "metadata": {
        "id": "tgQ19MI9FEkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(save_datas))"
      ],
      "metadata": {
        "id": "OkRms1zVF4bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "save_name = \"/content/ChatHaruhi_Chinese_New_Data.jsonl\"\n",
        "\n",
        "with open(save_name, 'w', encoding='utf8') as f:\n",
        "    for data in save_datas:\n",
        "        json.dump(data, f, ensure_ascii=False)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "3wW5RXl55VK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U_nKXIs957Oe"
      }
    }
  ]
}